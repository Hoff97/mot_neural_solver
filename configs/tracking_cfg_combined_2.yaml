ckpt_path: trained_models/graph_nets/mot_mpnet_epoch_006.ckpt
train_params:
  batch_size: 6 # default: 8
  num_epochs: 20
  optimizer:
    type: Adam
    args:
      lr: 0.001
      weight_decay: 0.0001
  loss:
    type: BCE

  lr_scheduler:
    type: StepLR
    args:
      step_size: 7
      gamma: 0.5

  num_workers: 6 # Used for dataloaders
  save_every_epoch: False # Determines if every checkpoint will be saved for every epoch
  save_epoch_start: 1 # If the arg above is set to True, determines the first epoch after which we start saving ckpts
  tensorboard: True

# Parameter search --> values of e.g. grid_search must be unique keys in this config file
parameter_search: grid_search
grid_search:
  num_epochs: [7]
  lr: [0.005, 0.0001, 0.0005]
  batch_size: [32]
  gamma: [0.3, 0.5, 0.7]

dataset_params:
  # define which model to use for joint detection (don't forget to rename the directory)
  debug: False # whether the dataset is being debugged (shows bounding box windows, keypoints etc.)
  keypoint_detection_model: keypointrcnn_resnet50

  combined_graph: True

  # Dataset Processing params:
  precomputed_embeddings:
    True # Determines whether CNN embeddings for nodes and reid are computed once, stored, and
    # then loaded when needed (True) or compute every time they are neede
  overwrite_processed_data:
    False # If True, sequence detects are processed again, and previous data is overwritten
    # (GT assignment, precomp embeddings (if they exist), processed dets file
  overwrite_joints: False # Like above, but for the joint detections
  precomputed_joints: True # Determines wether the joints per BB should be preprocessed
  det_file_name:
    tracktor_prepr_det # Name of the detections file used for val/test (matches the one created in preprocessing (see preprocessing.yaml)
    # e.g. change it for frcnn_prepr_det if not using tracktor for preprocessing
  node_embeddings_dir: resnet50_conv # Storage name for precomputing CNN node embeddings
  reid_embeddings_dir: resnet50_w_fc256 # Storage name for precomputing reid embeddings

  # Gt assignment
  gt_assign_min_iou: 0.5 # Min IoU between a GT and detected box so that an assignment is allowed
  # Parameters for heuristics used in MOT15 ground truth preprocessing for training
  GT_train_max_iou_containment_thresh: 0.85 # Maximum overlap that two boxes can have in order to be kept
  GT_train_max_iou_thresh: 0.75 # Maximum 'containment score' that a box can have in order to be kept (see mot_seqs.MOT15loader.py)

  # Data Augmentation Params
  augment: True # Determines whether data augmentation is performed
  min_iou_bb_wiggling: 0.8 # Minimum IoU w.r.t. original box used when doing
  min_ids_to_drop_perc: 0 # Minimum percentage of ids s.t. all of its detections will be dropped
  max_ids_to_drop_perc: 0.15 # Maximum percentage of ids s.t. all of its detections will be dropped
  min_detects_to_drop_perc: 0 # Minimum Percentage of detections that might be randomly dropped
  max_detects_to_drop_perc: 0.3 # Maximum Percentage of detections that might be randomly dropped
  p_change_fps_step: 0.5 # Probability of randomly changing the frame sampling rate during training

  # RGB params
  img_size: [128, 64] # Size at which bounding box images are resized
  img_batch_size: 500 # Batch size for evaluating
  visualize_joint_detections: True # Batch size for evaluating joint detector

  # Graph Construction Parameters
  gt_training_min_vis: 0.2 # Minimum visibility score allowed in a GT box to be used for training
  frames_per_graph: 15 # Maximum number of frames contained in each graph sampled graph
  max_frame_dist:
    max # Determines the maximum distance in num of frames between two detections in a graph connected
    # by an edge (setting it to a num is dangerous, as dist in frames depends on fps...) (should use seconds instead)
  min_detects: 25 # Minimum number of detections allowed so that a graph is sampled
  max_detects: 500 # Maximum number of detections allowed
  top_k_nns: 50 # Top K-nearest neighbors (w.r.t reid score) to which a node can be  connected in the graph
  reciprocal_k_nns:
    True # Indicates whether, connected nodes in the graph have to be
    # reciprocal NNs or not (i.e. (i, j) is an edge <--> i is a k-nn for j and
    # j is a k-nn for i
  edge_feats_to_use: # List of edge features to use (see 'compute_edge_feats_dict' in utils/graph.py
    # Time distance
    - secs_time_dists
    # Coordinate distances (differences)
    - norm_feet_x_dists
    - norm_feet_y_dists
    # BB Size distances (Log-ratios)
    - bb_height_dists
    - bb_width_dists
    # ReID Score
    - emb_dist
  node_feats_to_use:
    - bb_positions

  target_fps_dict: # Frame sampling rate for sequences with static/moving camera
    moving: 9
    static: 6

data_splits: # See src/mot_neural_solver/data/splits.py
  train: ["mot15_train_gt", "mot17_split_2_train_gt"]
  val: "split_2_val"
  test: ["mot15_test", "mot17_test"]

eval_params:
  # Logging / Metrics reporting params
  tensorboard: True
  check_val_every_n_epoch: 1
  val_percent_check: 0.15 # Percentage of the entire dataset used each time that validation loss is computed
  mot_metrics_to_log:
    [
      "mota",
      "norm_mota",
      "idf1",
      "norm_idf1",
      "num_switches",
      "num_misses",
      "num_false_positives",
      "num_fragmentations",
      "constr_sr",
    ]
  metrics_to_log: ["loss", "precision", "recall", "constr_sr"]
  log_per_seq_metrics: False
  normalize_mot_metrics:
    True # Determines whether MOT results are computer via an oracle (i.e. GT labels), in order to
    # normalize results. (i.e. what is the best possible MOTA we could get with a set of dets?)
  mot_metrics_to_norm: ["mota", "idf1"]
  best_method_criteria: "idf1"

  # Inference Params
  max_dets_per_graph_seq:
    40000 # Entire sequences are split into smaller subsequences of up to max_dets_per_graph_seq
    # detections to avoid loading into (GPU) memory massive graphs.
  rounding_method: exact # Determines whether an LP is used for rounding ('exact') or a greedy heuristic ('greedy')
  solver_backend: pulp # Determines package used to solve the LP, (Gurobi requires a license, pulp does not)
  set_pruned_edges_to_inactive:
    False # Determines whether pruning an edge during inference has the same effect
    # as predicting it as being non-active, or as not predicting a value for it
    # (i.e. the averaging is only computed among the times the edge is not pruned)

  # Postprocessing parameters:
  use_tracktor_start_ends: True
  add_tracktor_detects: True
  min_track_len: 2

graph_model_params:
  node_agg_fn: "max"
  num_enc_steps: 12 # Number of message passing steps
  num_class_steps: 11 # Number of message passing steps during feature vectors are classified (after Message Passing)
  reattach_initial_nodes: False # Determines whether initially encoded node feats are used during node updates
  reattach_initial_edges: True # Determines whether initially encoded edge feats are used during node updates

  multi: True # Wether this should be a graph model with multiple node types

  node_types: ["bb", "joint"]

  encoder_feats_dict:
    edge_in_dims:
      bb-bb: 6
    edge_fc_dims:
      bb-bb: [18, 18]
    edge_out_dims:
      bb-bb: 16
      bb-joint: 0
      joint-joint: 0
    node_in_dims:
      bb: 2052
      joint: 3
    node_fc_dims:
      bb: [128]
      joint: [8]
    node_out_dims:
      bb: 32
      joint: 8
    dropout_p: 0
    use_batchnorm: False

  edge_model_feats_dict:
    fc_dims:
      bb-bb: [80, 16]
    dropout_p: 0
    use_batchnorm: False

  # In size is 2 * encoded nodes + 1 * encoded edges
  node_model_feats_dict:
    bb:
      message_modules:
        bb:
          time_aware:
            input_dim: 48
            fc_dims: [56, 32]
            dropout_p: 0
            use_batchnorm: False
        joint:
          input_dim: 8
          fc_dims: [8]
          dropout_p: 0
          use_batchnorm: False
      update_mlp:
        input_dim: 104
        fc_dims: [32]
        dropout_p: 0
        use_batchnorm: False
      args:
        append_self: True
    joint:
      message_modules:
        bb:
          input_dim: 32
          fc_dims: [16]
          dropout_p: 0
          use_batchnorm: False
        joint:
          input_dim: 8
          fc_dims: [8]
          dropout_p: 0
          use_batchnorm: False
      update_mlp:
        input_dim: 32
        fc_dims: [16, 8]
        dropout_p: 0
        use_batchnorm: False
      args:
        append_self: True

  classifier_feats_dict:
    edge_in_dims:
      bb-bb: 16
    edge_fc_dims:
      bb-bb: [8]
    edge_out_dims:
      bb-bb: 1
    dropout_p: 0
    use_batchnorm: False

  cnn_params:
    arch: resnet50
    model_weights_path:
      resnet50: trained_models/reid/resnet50_market_cuhk_duke.tar-232
